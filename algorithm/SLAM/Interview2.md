1. 如何对匹配好的点做进一步的处理，更好保证匹配效果

（1）确定匹配最大距离，汉明距离小于最小距离的两倍

（2）使用KNN-matching算法，令K=2。则每个match得到两个最接近的descriptor，然后计算最接近距离和次接近距离之间的比值，当比值大于既定值时，才作为最终match。

（3）RANSAC（使用RANSAC找到最佳单应性矩阵。由于这个函数使用的特征点同时包含正确和错误匹配点，因此计算的单应性矩阵依赖于二次投影的准确性）



2. 单目相机，F和H矩阵有何不同，E和F矩阵有何不同，只旋转不平移能不能求F，只旋转不平移能不能求H

E=t^R

$$
F = K^{-T} E K^{-1}
$$

H=R-t*nT/d

在相机只有旋转而没有平移的情况，此时t为0，E也将为0，导致无法求解R，这时可以使用单应矩阵H求旋转，但仅有旋转，无法三角化求深度。


3. 描述BA

BA的本质是一个优化模型，其目的是最小化重投影/光度误差，用于优化相机位姿和世界点。局部BA用于优化局部的相机位姿，提高跟踪的精确度；全局BA用于全局过程中的相机位姿，使相机经过长时间、长距离的移动之后，相机位姿还比较准确。BA是一个图优化模型，一般选择LM(Levenberg-Marquardt)算法并在此基础上利用BA模型的稀疏性进行计算；可以直接计算，也可以使用g2o或者Ceres等优化库进行计算。

Bundle Adjustment : 从视觉重建中提炼出最优的3D模型和相机参数（内参和外参），好似每一个特征点都会反射几束光线，当把相机位姿和特征点位置做出最优的调整后，这些光线都收束到相机相机光心。也就是根据相机的投影模型构造构造代价函数，利用非线性优化（比如高斯牛顿或列文伯格马夸而尔特）来求最优解，利用雅克比矩阵的稀疏性解增量方程，得到相机位姿和特征点3D位置的最优解。

BA可以分为基于滤波器的BA和基于迭代的BA



4. 描述PnP

Perspective-n-Points, PnP(P3P)提供了一种解决方案，它是一种由3D-2D的位姿求解方式，即需要已知匹配的3D点和图像2D点。目前遇到的场景主要有两个，其一是求解相机相对于某2维图像/3维物体的位姿；其二就是SLAM算法中估计相机位姿时通常需要PnP给出相机初始位姿。

在场景1中，我们通常输入的是物体在世界坐标系下的3D点以及这些3D点在图像上投影的2D点，因此求得的是相机坐标系相对于世界坐标系(Twc)的位姿

在场景2中，通常输入的是上一帧中的3D点（在上一帧的相机坐标系下表示的点）和这些3D点在当前帧中的投影得到的2D点，所以它求得的是当前帧相对于上一帧的位姿变换，如图所示：

两种情况本质上是相同的，都是基于已知3D点和对应的图像2D点求解相机运动的过程。



5. 描述下GN、LM方法

（1） GN：线搜索

将f（x）进行一阶泰勒展开，最后求解

线性方程H△x=b；

用JT*J近似H矩阵，省略H复杂的计算

过程；

稳定性差，可能不收敛；

（2） LM：信赖区域；

求解线性方程(H+λI)△x=b；

提供更稳定，更准确的增量



6. 如何处理关键帧

关键帧选取的指标主要有：

（1）跟踪质量（主要根据跟踪过程中搜索到的点数和搜索的点数比例）/共视特征点

（2）距离最近关键帧的距离是否足够远（空间）/运动

（3）距离上一关键帧的帧数是否足够多（时间）



7. 为什么要引入李群李代数

旋转矩阵自身是带有约束的，正交且行列式为1，他们作为优化变量时，会引入额外的约束，时优化变的困难，通过李群李代数的转换关系，把位姿估计变成无约束的优化问题。



8. 什么是极限约束

所谓极线约束就是说同一个点在两幅图像上的映射，已知左图映射点p1，那么右图映射点p2一定在相对于p1的极线上，这样可以减少待匹配的点数量。（画图解释）



9. 单目视觉slam中尺寸漂移是怎么产生的

单目相机根据一张图片无法得出一张图片中物体的实际大小，同理也就无法得出运动的尺度大小，这是产生尺度漂移的根源。而在优化过程中，单目相机使用对极几何中的三角测量原理，而三角测量中，极小的角度误差在累积之后深度不确定都会变得很大，从而无法保证尺度一致性。



10. SLAM中的绑架问题

绑架问题就是重定位，是指机器人在缺少之前位置信息的情况下，如何去确定当前位姿。例如当机器人被安置在一个已经构建好地图的环境中，但是并不知道它在地图中的相对位置，或者在移动过程中，由于传感器的暂时性功能故障或相机的快速移动，都导致机器人先前的位置信息的丢失，在这种情况下如何重新确定自己的位置。