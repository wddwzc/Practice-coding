# 第一章 Introduction

## 第2节 PCA 主成分分析

### PCA 主成分分析

应用：
- 降维
- 法向量估计
- 关键点检测
- 特征描述子

谱定理

瑞利熵

SVD的物理意义


* 输入:
* 输出:

处理过程:

1. 归一化:去中心
2. 做 $H = \hat{X} \hat{X}^T = U_r \Sigma^2 U_r^T$ 矩阵的SVD
3. 主成分向量 是 $U_r$ 的列

可以理解为是一个 基地置换过程,可以用来做维度压缩

可以把 n 维的数据转成 l 维度的一个主成分向量,  Eigenfaces

### Kernel PCA

问题:PCA是线性的

解决:转到高维空间

比如两个同心圆,把 二维坐标 转成是 三维坐标


## 第3节 Surface Normal and Filters

应用:

- 分割/聚类
- 平面检测
- 点云特征(可用于DL)

平面法向量:

1. 选取一个点 P
2. 找到邻域(用来定义这个plane)
3. PCA
4. 最小向量-对应平面
5. 曲率 ( $\lambda_3 / (\lambda_1 + \lambda_2 + \lambda_3)$ )


当出现噪声的时候怎么解决:

1. 根据问题选邻域:
   - 大radius:法向量更平滑,但可能被无关物体影响
   - 小radius: 法向量更sharper,但受噪声影响
2. 用其它特征做加权
   - lidar intensity
   - RGB values 
3. RANSAC
4. Deep Learning


### 滤波

**噪声去除**

- radius Outlier Removal
- statistical outlier removal

**降采样**

- 提速萝卜
- 最远点采样
- 法向量空间采样

**上采样/平滑/去噪**

- 双边滤波器(Bilateral Filter)



**radius Outlier Removal**

取邻域,点少于一定数量,去除

**statistical outlier removal**

取邻域,计算每个点到邻域点的平均距离的均值,并计算方差

用高斯模型描述

去除 到邻域平均距离 超过 $3 \sigma$ 的点

**体素滤波-降采样**

每个体素里取一个点

选哪个点:

- 质心(平均  带权重的投票   精确但慢)
- 随机选(快但不精确)

算法流程:

1. 求整块点云的最大最小值
2. 确定 voxel size
3. 计算grid索引 h = hx + hy * d + hz * d * d
4. 排序
5. 计算质心

流程优化:

1. 计算得到 voxel index 后,不一样
2. 用一个 hash 来把点(1W个)映射到容器 G(很少,比如100个)
3. 出现冲突的时候,把已有的先放到序列里

能比普通的快5倍左右

**Farthest Point Sampling 最远点采样**

1. 随便选初始
2. 计算剩余点到已选点最几点的举例
3. 选取距离最大的那个
4. 可以适应密度不均

**Normal Space Sampling**

会用在

1. 在法向量空间中构建一组容器(法向量方向类别)
2. 根据法向量把点都放到对应容器
3. 在每个容器里做均匀采样

**学习的方法做采样**



**Bilateral Filter 降采样 上采样 都可以做**

用一个高斯核,可以做图像平滑(模糊)

之所以叫双边滤波,是因为有两个高斯核

计算距离权重 $G_{\sigma_s}$ 和 intensity 权重 $G_{\sigma_r}$

对像素 p 应用双边滤波,得到 intensity

$$\begin{aligned}
B F[I]_{\mathrm{p}} &=\frac{1}{W_{\mathrm{p}}} \sum_{\mathbf{q} \in \mathcal{S}} G_{\sigma_{s}}(\|\mathbf{p}-\mathbf{q}\|) G_{\sigma_{r}}\left(I_{\mathbf{p}}-I_{\mathbf{q}}\right) I_{\mathbf{q}} \\
W_{\mathbf{p}} &=\sum_{\mathbf{q} \in \mathcal{S}} G_{\sigma_{s}}(\|\mathbf{p}-\mathbf{q}\|) G_{\sigma_{r}}\left(I_{\mathbf{p}}-I_{\mathbf{q}}\right)
\end{aligned}$$

lidar点云 和 image 对应后,因为点云稀疏,导致image很多没有深度



# 第二章 最近邻问题

为什么不用开源库:

1. 不够快,是通用库,没有专门对2D/3D做优化
2. 大多数开源octree效率都比较低
3. 没有GPU-based的库

为什么点云的最近邻比较困难:

- 图像很简单,可以索引
- 点云
  1. 无序
  2. 变成了三维,导致指数上升
  3. 数据量大 暴力搜索复杂度O(N^2)

比较重要的idea:

- 空间分割
  - 把空间分到不同区域
  - 只搜索某些区域
- 停止条件
  - 怎么跳过一些分区,对比 worst distance 和 区间边界
  - 直到root或区间包含了 worst distance


## 第1节 二叉搜索树

最坏的情况可能会变成链表

**平衡二叉树**

趋向平衡的方法

- 选取中位数作为root
- 红黑树
- 平衡树

迭代实现可以在GPU上用,栈不适合在GPU上用

就是写起来比较复杂

## 第2节 Kd-tree

k-dimensinal tree

从k维轮流做二叉树的split

- leaf_size 可能不为1,区域点少于size时构建leaf
- 通过对应轴的超平面做切分
- 递归

### 构建

超平面选取方式:

1. 分割位置是存在的点,中位数
2. 分割位置没有切到点

切分方式:

1. 轮流
2. 自适应

复杂度上没有区别,自适应可能更快一点

构建kd-tree的复杂度:

- 每层排序的复杂度比较高
  - 时间复杂度 O(nlognlogn)
  - 空间复杂度 O(kn+nlogn) 通过只在leaf存点,可以简化到 O(kn+n)
- 通过选取 中位数 替代排序
  - O(n)
- 通过构建平衡kd-tree,实现 O(knlogn)

方法

- 一些实际中很好使的简单方法
  - 选子集做排序
  - 选均值替代中值
- 保证平衡树

### 查找

流程:

- 从root开始
- 到达包含query point 的 leaf
- 找到 worst distance
- 然后回溯,通过对比 边界 和 wd,决定是否搜索其它区域

不同方式:

- radius:最坏距离固定
- kNN:维护一个min_k的序列,wd根据最大的那个距离动态更新

1NN 复杂度 O(logn)

kNN/radiusNN 复杂度比较难分析:

- 取决于点的分布
- 取决于 k 或 r
- 一般就 O(logn) 到 O(n)

## 第3节 Octree

专门为3D数据设计

在kdtree中,做不到直接判断NN search是否中止

Octree的效率会更高,因为不需要going back to root

### 构建

流程:

- 决定第一个octant尺度
- 决定是否进一步切分 octant
  - leaf_size
  - min_extent 阻止无限分割


### 查找


